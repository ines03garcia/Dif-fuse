Logging to results/test
creating model and diffusion...
creating data loader...
training...
loading model from checkpoint: /home/csantiago/Dif-fuse/results/test/model190000.pt...
loading optimizer state from checkpoint: /home/csantiago/Dif-fuse/results/test/opt190000.pt
loading EMA from checkpoint: /home/csantiago/Dif-fuse/results/test/ema_0.9999_190000.pt...
-------------------------
| grad_norm  | 0.389    |
| loss       | 0.0153   |
| loss_q0    | 0.0328   |
| loss_q1    | 0.0197   |
| loss_q2    | 0.00588  |
| loss_q3    | 0.00269  |
| mse        | 0.0153   |
| mse_q0     | 0.0328   |
| mse_q1     | 0.0197   |
| mse_q2     | 0.00588  |
| mse_q3     | 0.00269  |
| param_norm | 32.4     |
| samples    | 3.04e+06 |
| step       | 1.9e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 0.953    |
| loss       | 0.0189   |
| loss_q0    | 0.0502   |
| loss_q1    | 0.0183   |
| loss_q2    | 0.00487  |
| loss_q3    | 0.00261  |
| mse        | 0.0189   |
| mse_q0     | 0.0502   |
| mse_q1     | 0.0183   |
| mse_q2     | 0.00487  |
| mse_q3     | 0.00261  |
| param_norm | 31.7     |
| samples    | 3.2e+06  |
| step       | 2e+05    |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 0.957    |
| loss       | 0.0188   |
| loss_q0    | 0.0494   |
| loss_q1    | 0.0183   |
| loss_q2    | 0.00487  |
| loss_q3    | 0.0026   |
| mse        | 0.0188   |
| mse_q0     | 0.0494   |
| mse_q1     | 0.0183   |
| mse_q2     | 0.00487  |
| mse_q3     | 0.0026   |
| param_norm | 30.2     |
| samples    | 3.36e+06 |
| step       | 2.1e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.01     |
| loss       | 0.019    |
| loss_q0    | 0.0506   |
| loss_q1    | 0.0184   |
| loss_q2    | 0.00487  |
| loss_q3    | 0.00258  |
| mse        | 0.019    |
| mse_q0     | 0.0506   |
| mse_q1     | 0.0184   |
| mse_q2     | 0.00487  |
| mse_q3     | 0.00258  |
| param_norm | 28.8     |
| samples    | 3.52e+06 |
| step       | 2.2e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.06     |
| loss       | 0.0192   |
| loss_q0    | 0.0511   |
| loss_q1    | 0.0185   |
| loss_q2    | 0.00486  |
| loss_q3    | 0.00256  |
| mse        | 0.0192   |
| mse_q0     | 0.0511   |
| mse_q1     | 0.0185   |
| mse_q2     | 0.00486  |
| mse_q3     | 0.00256  |
| param_norm | 27.4     |
| samples    | 3.68e+06 |
| step       | 2.3e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.1      |
| loss       | 0.0193   |
| loss_q0    | 0.0512   |
| loss_q1    | 0.0186   |
| loss_q2    | 0.00485  |
| loss_q3    | 0.00254  |
| mse        | 0.0193   |
| mse_q0     | 0.0512   |
| mse_q1     | 0.0186   |
| mse_q2     | 0.00485  |
| mse_q3     | 0.00254  |
| param_norm | 26.2     |
| samples    | 3.84e+06 |
| step       | 2.4e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.14     |
| loss       | 0.0193   |
| loss_q0    | 0.0512   |
| loss_q1    | 0.0186   |
| loss_q2    | 0.00483  |
| loss_q3    | 0.00252  |
| mse        | 0.0193   |
| mse_q0     | 0.0512   |
| mse_q1     | 0.0186   |
| mse_q2     | 0.00483  |
| mse_q3     | 0.00252  |
| param_norm | 24.9     |
| samples    | 4e+06    |
| step       | 2.5e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.19     |
| loss       | 0.0195   |
| loss_q0    | 0.052    |
| loss_q1    | 0.0187   |
| loss_q2    | 0.00482  |
| loss_q3    | 0.0025   |
| mse        | 0.0195   |
| mse_q0     | 0.052    |
| mse_q1     | 0.0187   |
| mse_q2     | 0.00482  |
| mse_q3     | 0.0025   |
| param_norm | 23.8     |
| samples    | 4.16e+06 |
| step       | 2.6e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.23     |
| loss       | 0.0197   |
| loss_q0    | 0.0526   |
| loss_q1    | 0.0188   |
| loss_q2    | 0.00482  |
| loss_q3    | 0.00249  |
| mse        | 0.0197   |
| mse_q0     | 0.0526   |
| mse_q1     | 0.0188   |
| mse_q2     | 0.00482  |
| mse_q3     | 0.00249  |
| param_norm | 22.7     |
| samples    | 4.32e+06 |
| step       | 2.7e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.29     |
| loss       | 0.0197   |
| loss_q0    | 0.0525   |
| loss_q1    | 0.0188   |
| loss_q2    | 0.00481  |
| loss_q3    | 0.00248  |
| mse        | 0.0197   |
| mse_q0     | 0.0525   |
| mse_q1     | 0.0188   |
| mse_q2     | 0.00481  |
| mse_q3     | 0.00248  |
| param_norm | 21.7     |
| samples    | 4.48e+06 |
| step       | 2.8e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.32     |
| loss       | 0.0198   |
| loss_q0    | 0.0529   |
| loss_q1    | 0.0189   |
| loss_q2    | 0.0048   |
| loss_q3    | 0.00245  |
| mse        | 0.0198   |
| mse_q0     | 0.0529   |
| mse_q1     | 0.0189   |
| mse_q2     | 0.0048   |
| mse_q3     | 0.00245  |
| param_norm | 20.7     |
| samples    | 4.64e+06 |
| step       | 2.9e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.37     |
| loss       | 0.0198   |
| loss_q0    | 0.053    |
| loss_q1    | 0.019    |
| loss_q2    | 0.00482  |
| loss_q3    | 0.00244  |
| mse        | 0.0198   |
| mse_q0     | 0.053    |
| mse_q1     | 0.019    |
| mse_q2     | 0.00482  |
| mse_q3     | 0.00244  |
| param_norm | 19.8     |
| samples    | 4.8e+06  |
| step       | 3e+05    |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.45     |
| loss       | 0.0201   |
| loss_q0    | 0.0538   |
| loss_q1    | 0.0191   |
| loss_q2    | 0.00481  |
| loss_q3    | 0.00244  |
| mse        | 0.0201   |
| mse_q0     | 0.0538   |
| mse_q1     | 0.0191   |
| mse_q2     | 0.00481  |
| mse_q3     | 0.00244  |
| param_norm | 18.9     |
| samples    | 4.96e+06 |
| step       | 3.1e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.46     |
| loss       | 0.0201   |
| loss_q0    | 0.0539   |
| loss_q1    | 0.0192   |
| loss_q2    | 0.00483  |
| loss_q3    | 0.00243  |
| mse        | 0.0201   |
| mse_q0     | 0.0539   |
| mse_q1     | 0.0192   |
| mse_q2     | 0.00483  |
| mse_q3     | 0.00243  |
| param_norm | 18.1     |
| samples    | 5.12e+06 |
| step       | 3.2e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.56     |
| loss       | 0.0204   |
| loss_q0    | 0.0548   |
| loss_q1    | 0.0192   |
| loss_q2    | 0.00483  |
| loss_q3    | 0.00245  |
| mse        | 0.0204   |
| mse_q0     | 0.0548   |
| mse_q1     | 0.0192   |
| mse_q2     | 0.00483  |
| mse_q3     | 0.00245  |
| param_norm | 17.3     |
| samples    | 5.28e+06 |
| step       | 3.3e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.65     |
| loss       | 0.0203   |
| loss_q0    | 0.055    |
| loss_q1    | 0.0192   |
| loss_q2    | 0.00484  |
| loss_q3    | 0.00244  |
| mse        | 0.0203   |
| mse_q0     | 0.055    |
| mse_q1     | 0.0192   |
| mse_q2     | 0.00484  |
| mse_q3     | 0.00244  |
| param_norm | 16.6     |
| samples    | 5.44e+06 |
| step       | 3.4e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.76     |
| loss       | 0.0203   |
| loss_q0    | 0.0547   |
| loss_q1    | 0.0193   |
| loss_q2    | 0.00487  |
| loss_q3    | 0.00245  |
| mse        | 0.0203   |
| mse_q0     | 0.0547   |
| mse_q1     | 0.0193   |
| mse_q2     | 0.00487  |
| mse_q3     | 0.00245  |
| param_norm | 15.9     |
| samples    | 5.6e+06  |
| step       | 3.5e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.95     |
| loss       | 0.0205   |
| loss_q0    | 0.0553   |
| loss_q1    | 0.0193   |
| loss_q2    | 0.00484  |
| loss_q3    | 0.00246  |
| mse        | 0.0205   |
| mse_q0     | 0.0553   |
| mse_q1     | 0.0193   |
| mse_q2     | 0.00484  |
| mse_q3     | 0.00246  |
| param_norm | 15.3     |
| samples    | 5.76e+06 |
| step       | 3.6e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.09     |
| loss       | 0.0207   |
| loss_q0    | 0.0562   |
| loss_q1    | 0.0194   |
| loss_q2    | 0.00484  |
| loss_q3    | 0.00244  |
| mse        | 0.0207   |
| mse_q0     | 0.0562   |
| mse_q1     | 0.0194   |
| mse_q2     | 0.00484  |
| mse_q3     | 0.00244  |
| param_norm | 14.7     |
| samples    | 5.92e+06 |
| step       | 3.7e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.24     |
| loss       | 0.0207   |
| loss_q0    | 0.0566   |
| loss_q1    | 0.0194   |
| loss_q2    | 0.00484  |
| loss_q3    | 0.00242  |
| mse        | 0.0207   |
| mse_q0     | 0.0566   |
| mse_q1     | 0.0194   |
| mse_q2     | 0.00484  |
| mse_q3     | 0.00242  |
| param_norm | 14.1     |
| samples    | 6.08e+06 |
| step       | 3.8e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.44     |
| loss       | 0.021    |
| loss_q0    | 0.0578   |
| loss_q1    | 0.0195   |
| loss_q2    | 0.00483  |
| loss_q3    | 0.0024   |
| mse        | 0.021    |
| mse_q0     | 0.0578   |
| mse_q1     | 0.0195   |
| mse_q2     | 0.00483  |
| mse_q3     | 0.0024   |
| param_norm | 13.6     |
| samples    | 6.24e+06 |
| step       | 3.9e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.56     |
| loss       | 0.0211   |
| loss_q0    | 0.0575   |
| loss_q1    | 0.0196   |
| loss_q2    | 0.0048   |
| loss_q3    | 0.00238  |
| mse        | 0.0211   |
| mse_q0     | 0.0575   |
| mse_q1     | 0.0196   |
| mse_q2     | 0.0048   |
| mse_q3     | 0.00238  |
| param_norm | 13.1     |
| samples    | 6.4e+06  |
| step       | 4e+05    |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.71     |
| loss       | 0.0213   |
| loss_q0    | 0.0586   |
| loss_q1    | 0.0196   |
| loss_q2    | 0.00479  |
| loss_q3    | 0.00235  |
| mse        | 0.0213   |
| mse_q0     | 0.0586   |
| mse_q1     | 0.0196   |
| mse_q2     | 0.00479  |
| mse_q3     | 0.00235  |
| param_norm | 12.6     |
| samples    | 6.56e+06 |
| step       | 4.1e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.78     |
| loss       | 0.0215   |
| loss_q0    | 0.0594   |
| loss_q1    | 0.0197   |
| loss_q2    | 0.0048   |
| loss_q3    | 0.00232  |
| mse        | 0.0215   |
| mse_q0     | 0.0594   |
| mse_q1     | 0.0197   |
| mse_q2     | 0.0048   |
| mse_q3     | 0.00232  |
| param_norm | 12.2     |
| samples    | 6.72e+06 |
| step       | 4.2e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.93     |
| loss       | 0.0215   |
| loss_q0    | 0.0591   |
| loss_q1    | 0.0198   |
| loss_q2    | 0.00479  |
| loss_q3    | 0.00231  |
| mse        | 0.0215   |
| mse_q0     | 0.0591   |
| mse_q1     | 0.0198   |
| mse_q2     | 0.00479  |
| mse_q3     | 0.00231  |
| param_norm | 11.8     |
| samples    | 6.88e+06 |
| step       | 4.3e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.92     |
| loss       | 0.0218   |
| loss_q0    | 0.0598   |
| loss_q1    | 0.0198   |
| loss_q2    | 0.00478  |
| loss_q3    | 0.0023   |
| mse        | 0.0218   |
| mse_q0     | 0.0598   |
| mse_q1     | 0.0198   |
| mse_q2     | 0.00478  |
| mse_q3     | 0.0023   |
| param_norm | 11.5     |
| samples    | 7.04e+06 |
| step       | 4.4e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 3.02     |
| loss       | 0.0218   |
| loss_q0    | 0.0601   |
| loss_q1    | 0.0199   |
| loss_q2    | 0.00479  |
| loss_q3    | 0.00229  |
| mse        | 0.0218   |
| mse_q0     | 0.0601   |
| mse_q1     | 0.0199   |
| mse_q2     | 0.00479  |
| mse_q3     | 0.00229  |
| param_norm | 11.1     |
| samples    | 7.2e+06  |
| step       | 4.5e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 3.01     |
| loss       | 0.0221   |
| loss_q0    | 0.0611   |
| loss_q1    | 0.0199   |
| loss_q2    | 0.00478  |
| loss_q3    | 0.00228  |
| mse        | 0.0221   |
| mse_q0     | 0.0611   |
| mse_q1     | 0.0199   |
| mse_q2     | 0.00478  |
| mse_q3     | 0.00228  |
| param_norm | 10.8     |
| samples    | 7.36e+06 |
| step       | 4.6e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.86     |
| loss       | 0.0222   |
| loss_q0    | 0.0622   |
| loss_q1    | 0.02     |
| loss_q2    | 0.00476  |
| loss_q3    | 0.00224  |
| mse        | 0.0222   |
| mse_q0     | 0.0622   |
| mse_q1     | 0.02     |
| mse_q2     | 0.00476  |
| mse_q3     | 0.00224  |
| param_norm | 10.5     |
| samples    | 7.52e+06 |
| step       | 4.7e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.63     |
| loss       | 0.0222   |
| loss_q0    | 0.0616   |
| loss_q1    | 0.0201   |
| loss_q2    | 0.00477  |
| loss_q3    | 0.00223  |
| mse        | 0.0222   |
| mse_q0     | 0.0616   |
| mse_q1     | 0.0201   |
| mse_q2     | 0.00477  |
| mse_q3     | 0.00223  |
| param_norm | 10.2     |
| samples    | 7.68e+06 |
| step       | 4.8e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 2.29     |
| loss       | 0.0224   |
| loss_q0    | 0.0626   |
| loss_q1    | 0.0202   |
| loss_q2    | 0.00479  |
| loss_q3    | 0.00221  |
| mse        | 0.0224   |
| mse_q0     | 0.0626   |
| mse_q1     | 0.0202   |
| mse_q2     | 0.00479  |
| mse_q3     | 0.00221  |
| param_norm | 9.97     |
| samples    | 7.84e+06 |
| step       | 4.9e+05  |
-------------------------
saving model 0...
saving model 0.9999...
-------------------------
| grad_norm  | 1.96     |
| loss       | 0.0229   |
| loss_q0    | 0.0641   |
| loss_q1    | 0.0203   |
| loss_q2    | 0.00479  |
| loss_q3    | 0.00221  |
| mse        | 0.0229   |
| mse_q0     | 0.0641   |
| mse_q1     | 0.0203   |
| mse_q2     | 0.00479  |
| mse_q3     | 0.00221  |
| param_norm | 9.73     |
| samples    | 8e+06    |
| step       | 5e+05    |
-------------------------
saving model 0...
saving model 0.9999...
